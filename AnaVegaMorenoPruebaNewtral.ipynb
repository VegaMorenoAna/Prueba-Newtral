{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de AnaVegaMorenoPruebaNewtral.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VegaMorenoAna/Prueba-Newtral/blob/main/AnaVegaMorenoPruebaNewtral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ana Vega Moreno**"
      ],
      "metadata": {
        "id": "2g1yCHMes0ol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar instalamos las librerías que vamos a necesitar e importamos lo necesario de cada una de ellas."
      ],
      "metadata": {
        "id": "iCotqR0As74H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmLULgoYX24P",
        "outputId": "d9c61d85-57f9-47be-baa7-0a9eab5f2304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers numpy torch sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "crO05E3cdSsX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para que siempre aporte los mismos resultados creamos una función para fijar la semilla."
      ],
      "metadata": {
        "id": "Ogz4e0httnTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int):\n",
        "    \"\"\"\n",
        "    Función para fijar la semilla.\n",
        "\n",
        "    Args:\n",
        "        seed (:obj:`int`): Número que representa la semilla a fijar.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if is_torch_available():\n",
        "        torch.manual_seed(seed)\n",
        "    if is_tf_available():\n",
        "        import tensorflow as tf\n",
        "\n",
        "        tf.random.set_seed(seed)\n",
        "\n",
        "set_seed(1)"
      ],
      "metadata": {
        "id": "7r1dNJrvd-qA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Permito a google colab que acceda a mi drive, que es donde tengo los archivos csv."
      ],
      "metadata": {
        "id": "rEusuCVuwjxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls /content/drive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3sBfk9ymhZI",
        "outputId": "1886adbe-1a06-48b2-b347-07c2af294bad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los datos\n",
        "train = pd.read_csv('/content/drive/MyDrive/webis_train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/webis_test.csv')"
      ],
      "metadata": {
        "id": "pNohj-lKkeUT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestro como vienen los datasets.\n",
        "train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "6cYgEwG3yJ5Q",
        "outputId": "ffd26800-e367-4c26-c437-6df390d06f4e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 postMedia                                           postText  \\\n",
              "0           0        []  UK’s response to modern slavery leaving victim...   \n",
              "1           1        []                                       this is good   \n",
              "2           2        []  The \"forgotten\" Trump roast: Relive his brutal...   \n",
              "\n",
              "                   id                                     targetCaptions  \\\n",
              "0  858462320779026432                         ['modern-slavery-rex.jpg']   \n",
              "1  858421020331560960  ['In this July 1, 2010 file photo, Dr. Charmai...   \n",
              "2  858368123753435136  [\"President Trump will not attend this year's ...   \n",
              "\n",
              "                                    targetParagraphs  \\\n",
              "0  ['Thousands of modern slavery victims have\\xa0...   \n",
              "1  ['President Donald Trump has appointed the\\xa0...   \n",
              "2  ['When the\\xa0White House correspondents’ dinn...   \n",
              "\n",
              "                                         targetTitle  \\\n",
              "0  ‘Inexcusable’ failures in UK’s response to mod...   \n",
              "1  Donald Trump Appoints Pro-Life Advocate as Ass...   \n",
              "2  The ‘forgotten’ Trump roast: Relive his brutal...   \n",
              "\n",
              "                    postTimestamp  \\\n",
              "0  Sat Apr 29 23:25:41 +0000 2017   \n",
              "1  Sat Apr 29 20:41:34 +0000 2017   \n",
              "2  Sat Apr 29 17:11:23 +0000 2017   \n",
              "\n",
              "                                      targetKeywords  \\\n",
              "0  modern slavery, Department For Work And Pensio...   \n",
              "1  Americans United for Life, Dr. Charmaine Yoest...   \n",
              "2  trump whcd, whcd, white house correspondents d...   \n",
              "\n",
              "                                   targetDescription  \\\n",
              "0  “Inexcusable” failures in the UK’s system for ...   \n",
              "1  President Donald Trump has appointed pro-life ...   \n",
              "2  President Trump won't be at this year's White ...   \n",
              "\n",
              "                                      truthJudgments  truthMean    truthClass  \\\n",
              "0  [0.33333333330000003, 0.0, 0.33333333330000003...   0.133333  no-clickbait   \n",
              "1                          [1.0, 1.0, 1.0, 1.0, 1.0]   1.000000     clickbait   \n",
              "2  [0.33333333330000003, 1.0, 0.33333333330000003...   0.466667  no-clickbait   \n",
              "\n",
              "   truthMedian  truthMode  \n",
              "0     0.000000   0.000000  \n",
              "1     1.000000   1.000000  \n",
              "2     0.333333   0.333333  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bdf9086-70bf-4201-b8e4-f99112b6bef8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>postMedia</th>\n",
              "      <th>postText</th>\n",
              "      <th>id</th>\n",
              "      <th>targetCaptions</th>\n",
              "      <th>targetParagraphs</th>\n",
              "      <th>targetTitle</th>\n",
              "      <th>postTimestamp</th>\n",
              "      <th>targetKeywords</th>\n",
              "      <th>targetDescription</th>\n",
              "      <th>truthJudgments</th>\n",
              "      <th>truthMean</th>\n",
              "      <th>truthClass</th>\n",
              "      <th>truthMedian</th>\n",
              "      <th>truthMode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>UK’s response to modern slavery leaving victim...</td>\n",
              "      <td>858462320779026432</td>\n",
              "      <td>['modern-slavery-rex.jpg']</td>\n",
              "      <td>['Thousands of modern slavery victims have\\xa0...</td>\n",
              "      <td>‘Inexcusable’ failures in UK’s response to mod...</td>\n",
              "      <td>Sat Apr 29 23:25:41 +0000 2017</td>\n",
              "      <td>modern slavery, Department For Work And Pensio...</td>\n",
              "      <td>“Inexcusable” failures in the UK’s system for ...</td>\n",
              "      <td>[0.33333333330000003, 0.0, 0.33333333330000003...</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>no-clickbait</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td>this is good</td>\n",
              "      <td>858421020331560960</td>\n",
              "      <td>['In this July 1, 2010 file photo, Dr. Charmai...</td>\n",
              "      <td>['President Donald Trump has appointed the\\xa0...</td>\n",
              "      <td>Donald Trump Appoints Pro-Life Advocate as Ass...</td>\n",
              "      <td>Sat Apr 29 20:41:34 +0000 2017</td>\n",
              "      <td>Americans United for Life, Dr. Charmaine Yoest...</td>\n",
              "      <td>President Donald Trump has appointed pro-life ...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>clickbait</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[]</td>\n",
              "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
              "      <td>858368123753435136</td>\n",
              "      <td>[\"President Trump will not attend this year's ...</td>\n",
              "      <td>['When the\\xa0White House correspondents’ dinn...</td>\n",
              "      <td>The ‘forgotten’ Trump roast: Relive his brutal...</td>\n",
              "      <td>Sat Apr 29 17:11:23 +0000 2017</td>\n",
              "      <td>trump whcd, whcd, white house correspondents d...</td>\n",
              "      <td>President Trump won't be at this year's White ...</td>\n",
              "      <td>[0.33333333330000003, 1.0, 0.33333333330000003...</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>no-clickbait</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bdf9086-70bf-4201-b8e4-f99112b6bef8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0bdf9086-70bf-4201-b8e4-f99112b6bef8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0bdf9086-70bf-4201-b8e4-f99112b6bef8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "IX99_1uayN7E",
        "outputId": "61615359-e3ce-4ff8-fd0a-29453bff86bc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                  id                               postMedia  \\\n",
              "0           0  858426904239497216  ['media/photo_858425825229549568.jpg']   \n",
              "1           1  858416350540201984  ['media/photo_858416342268911616.jpg']   \n",
              "2           2  858364015260704768                                      []   \n",
              "\n",
              "                                      targetCaptions  \\\n",
              "0  ['Cleveland Browns logo', 'Dec 6, 2015; Clevel...   \n",
              "1           ['Five', 'Guilfoyle', 'Coulter', 'Cain']   \n",
              "2                                                 []   \n",
              "\n",
              "                                            postText  \\\n",
              "0  Johnny Manziel on Browns' No. 1 pick Myles Gar...   \n",
              "1  Fabio: California Is a 'Mess' Because of Liber...   \n",
              "2            \"He's been huge for us this year, man.\"   \n",
              "\n",
              "                    postTimestamp  \\\n",
              "0  Sat Apr 29 21:04:57 +0000 2017   \n",
              "1  Sat Apr 29 20:23:01 +0000 2017   \n",
              "2  Sat Apr 29 16:55:03 +0000 2017   \n",
              "\n",
              "                                         targetTitle  \\\n",
              "0  Johnny Manziel Says Top Pick in Draft Myles Ga...   \n",
              "1  Fabio: California Is a 'Mess' Because of Liber...   \n",
              "2  Jimmy Butler wants to return, hopes Bulls keep...   \n",
              "\n",
              "                                   targetDescription  \\\n",
              "0  Johnny   Manziel   approves of the  Cleveland ...   \n",
              "1  Fabio, the Italian-born male model who has ado...   \n",
              "2  Bulls guard Jimmy Butler says he wants to rema...   \n",
              "\n",
              "                                      targetKeywords  \\\n",
              "0  NFL Draft, Football, NFL, AFC North, Cleveland...   \n",
              "1                                                NaN   \n",
              "2  guards, backcourt, option, contract, Chicago B...   \n",
              "\n",
              "                                    targetParagraphs  \\\n",
              "0  [\"Johnny Manziel approves of the Cleveland Bro...   \n",
              "1  ['Fabio, the Italian-born male model who has a...   \n",
              "2  [\"CHICAGO -- All-Star swingman Jimmy Butler kn...   \n",
              "\n",
              "                              truthJudgments    truthClass  truthMedian  \\\n",
              "0                  [0.0, 0.0, 0.0, 0.0, 0.0]  no-clickbait          0.0   \n",
              "1  [0.0, 0.0, 0.0, 0.33333333330000003, 0.0]  no-clickbait          0.0   \n",
              "2                  [1.0, 1.0, 1.0, 1.0, 1.0]     clickbait          1.0   \n",
              "\n",
              "   truthMode  truthMean  \n",
              "0        0.0   0.000000  \n",
              "1        0.0   0.066667  \n",
              "2        1.0   1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85cd7aeb-92ec-4e60-93eb-879b85e0fd2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>postMedia</th>\n",
              "      <th>targetCaptions</th>\n",
              "      <th>postText</th>\n",
              "      <th>postTimestamp</th>\n",
              "      <th>targetTitle</th>\n",
              "      <th>targetDescription</th>\n",
              "      <th>targetKeywords</th>\n",
              "      <th>targetParagraphs</th>\n",
              "      <th>truthJudgments</th>\n",
              "      <th>truthClass</th>\n",
              "      <th>truthMedian</th>\n",
              "      <th>truthMode</th>\n",
              "      <th>truthMean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>858426904239497216</td>\n",
              "      <td>['media/photo_858425825229549568.jpg']</td>\n",
              "      <td>['Cleveland Browns logo', 'Dec 6, 2015; Clevel...</td>\n",
              "      <td>Johnny Manziel on Browns' No. 1 pick Myles Gar...</td>\n",
              "      <td>Sat Apr 29 21:04:57 +0000 2017</td>\n",
              "      <td>Johnny Manziel Says Top Pick in Draft Myles Ga...</td>\n",
              "      <td>Johnny   Manziel   approves of the  Cleveland ...</td>\n",
              "      <td>NFL Draft, Football, NFL, AFC North, Cleveland...</td>\n",
              "      <td>[\"Johnny Manziel approves of the Cleveland Bro...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>no-clickbait</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>858416350540201984</td>\n",
              "      <td>['media/photo_858416342268911616.jpg']</td>\n",
              "      <td>['Five', 'Guilfoyle', 'Coulter', 'Cain']</td>\n",
              "      <td>Fabio: California Is a 'Mess' Because of Liber...</td>\n",
              "      <td>Sat Apr 29 20:23:01 +0000 2017</td>\n",
              "      <td>Fabio: California Is a 'Mess' Because of Liber...</td>\n",
              "      <td>Fabio, the Italian-born male model who has ado...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Fabio, the Italian-born male model who has a...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.33333333330000003, 0.0]</td>\n",
              "      <td>no-clickbait</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>858364015260704768</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>\"He's been huge for us this year, man.\"</td>\n",
              "      <td>Sat Apr 29 16:55:03 +0000 2017</td>\n",
              "      <td>Jimmy Butler wants to return, hopes Bulls keep...</td>\n",
              "      <td>Bulls guard Jimmy Butler says he wants to rema...</td>\n",
              "      <td>guards, backcourt, option, contract, Chicago B...</td>\n",
              "      <td>[\"CHICAGO -- All-Star swingman Jimmy Butler kn...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "      <td>clickbait</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85cd7aeb-92ec-4e60-93eb-879b85e0fd2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85cd7aeb-92ec-4e60-93eb-879b85e0fd2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85cd7aeb-92ec-4e60-93eb-879b85e0fd2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Formato de los datos\n",
        "print(type(train))\n",
        "print(type(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYAR-zzTxiKX",
        "outputId": "416faf6b-83ce-449f-905d-7379611669bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos cuantas filas y cuantas columnas contiene train\n",
        "print(\"El dataframe contiene un total de {} filas\".format(len(train)))\n",
        "print(\"El dataframe contiene un total de {} columnas\".format(train.shape[1]))\n",
        "# Las filas también podrían calcularse de la siguiente manera\n",
        "print(\"El dataframe contiene un total de {} filas\".format(train.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCCNroqBxvdz",
        "outputId": "4f8ef2d2-5e00-436e-be4d-feb9c0a2edb5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El dataframe contiene un total de 19538 filas\n",
            "El dataframe contiene un total de 15 columnas\n",
            "El dataframe contiene un total de 19538 filas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos cuantas filas y cuantas columnas contiene test\n",
        "print(\"El dataframe contiene un total de {} filas\".format(len(test)))\n",
        "print(\"El dataframe contiene un total de {} columnas\".format(test.shape[1]))\n",
        "# Las filas también podrían calcularse de la siguiente manera\n",
        "print(\"El dataframe contiene un total de {} filas\".format(test.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxMGx1wZx2no",
        "outputId": "f7023393-29a2-4ba9-de79-a701269c06d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El dataframe contiene un total de 18979 filas\n",
            "El dataframe contiene un total de 15 columnas\n",
            "El dataframe contiene un total de 18979 filas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos si existen duplicados en train\n",
        "print(\"Existen {} documentos duplicadas\".format(np.sum(train.duplicated(subset=[\"postText\"]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1NGvFIPx97i",
        "outputId": "1ce23d0b-212a-440a-ad84-9d30601e1c00"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existen 456 documentos duplicadas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quitaremos esos duplicados\n",
        "train = train.drop_duplicates(subset=[\"postText\"])\n",
        "print(\"Después de quitar duplicados tenemos un conjunto de {} post\".format(train.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb16ogqMyeNj",
        "outputId": "4962d948-7957-43e5-84c1-2cf761577a5c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Después de quitar duplicados tenemos un conjunto de 19082 post\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos si existen duplicados en test\n",
        "print(\"Existen {} documentos duplicadas\".format(np.sum(test.duplicated(subset=[\"postText\"]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x1CH3PbyZjG",
        "outputId": "e5be6d41-7f44-456d-d650-e602604a331c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existen 445 documentos duplicadas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quitaremos esos duplicados\n",
        "test = test.drop_duplicates(subset=[\"postText\"])\n",
        "print(\"Después de quitar duplicados tenemos un conjunto de {} post\".format(test.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVS7wf3eytQc",
        "outputId": "a44ca2ea-329d-48a9-df23-06f23c1a944c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Después de quitar duplicados tenemos un conjunto de 18534 post\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPentKij1JPS",
        "outputId": "3a64f4ba-7e6f-4e14-81c4-5c5deb923f26"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Unnamed: 0', 'postMedia', 'postText', 'id', 'targetCaptions',\n",
              "       'targetParagraphs', 'targetTitle', 'postTimestamp',\n",
              "       'targetKeywords', 'targetDescription', 'truthJudgments',\n",
              "       'truthMean', 'truthClass', 'truthMedian', 'truthMode'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos las columnas que no necesitamos\n",
        "train = train.drop(['Unnamed: 0', 'postMedia', 'id', 'targetCaptions',\n",
        "                    'targetParagraphs', 'targetTitle', 'postTimestamp',\n",
        "                    'targetKeywords', 'targetDescription', 'truthJudgments',\n",
        "                    'truthMean', 'truthMedian', 'truthMode'], axis=1)"
      ],
      "metadata": {
        "id": "qNKxD4iT06ky"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "02_PuRNz11mA",
        "outputId": "5a8dc109-63d7-470a-f23f-77c80fb57159"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            postText    truthClass\n",
              "0  UK’s response to modern slavery leaving victim...  no-clickbait\n",
              "1                                       this is good     clickbait\n",
              "2  The \"forgotten\" Trump roast: Relive his brutal...  no-clickbait"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d414a4c4-0225-465f-9184-0a66570d2915\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>postText</th>\n",
              "      <th>truthClass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UK’s response to modern slavery leaving victim...</td>\n",
              "      <td>no-clickbait</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this is good</td>\n",
              "      <td>clickbait</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
              "      <td>no-clickbait</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d414a4c4-0225-465f-9184-0a66570d2915')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d414a4c4-0225-465f-9184-0a66570d2915 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d414a4c4-0225-465f-9184-0a66570d2915');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos si existen valores vacios en train \n",
        "print(\"Hay {} valores vacíos en postText y {} valores vacíos en las etiquetas en los datos\".format(np.sum(train.isnull())[0],\n",
        "                                                                                                   np.sum(train.isnull())[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptj2oH0BzVU8",
        "outputId": "a2eed692-0e83-483f-e55e-7d0ceb164285"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hay 1 valores vacíos en postText y 0 valores vacíos en las etiquetas en los datos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.dropna()"
      ],
      "metadata": {
        "id": "V2Of6ug-2qer"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos  que se han eliminado\n",
        "print(\"Hay {} valores vacíos en postText y {} valores vacíos en las etiquetas en los datos\".format(np.sum(train.isnull())[0],\n",
        "                                                                                                   np.sum(train.isnull())[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMIWu__j2vxt",
        "outputId": "a797c180-34aa-484d-f718-236bd04722c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hay 0 valores vacíos en postText y 0 valores vacíos en las etiquetas en los datos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.columns.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAzuDclJ1nUk",
        "outputId": "a5628e9c-226f-4180-8c82-a409278f73ea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Unnamed: 0', 'id', 'postMedia', 'targetCaptions', 'postText',\n",
              "       'postTimestamp', 'targetTitle', 'targetDescription',\n",
              "       'targetKeywords', 'targetParagraphs', 'truthJudgments',\n",
              "       'truthClass', 'truthMedian', 'truthMode', 'truthMean'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos las columnas que no necesitamos\n",
        "test = test.drop(['Unnamed: 0', 'id', 'postMedia', 'targetCaptions',\n",
        "                    'postTimestamp', 'targetTitle', 'targetDescription',\n",
        "                    'targetKeywords', 'targetParagraphs', 'truthJudgments',\n",
        "                    'truthMedian', 'truthMode', 'truthMean'], axis=1)"
      ],
      "metadata": {
        "id": "agoLMMY21qop"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "pejly8sq15b0",
        "outputId": "cb187274-e908-4743-8e37-7f7dea3e9a21"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            postText    truthClass\n",
              "0  Johnny Manziel on Browns' No. 1 pick Myles Gar...  no-clickbait\n",
              "1  Fabio: California Is a 'Mess' Because of Liber...  no-clickbait\n",
              "2            \"He's been huge for us this year, man.\"     clickbait"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32a7abbe-4ca4-44d0-8067-f5eec66b958c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>postText</th>\n",
              "      <th>truthClass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Johnny Manziel on Browns' No. 1 pick Myles Gar...</td>\n",
              "      <td>no-clickbait</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fabio: California Is a 'Mess' Because of Liber...</td>\n",
              "      <td>no-clickbait</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"He's been huge for us this year, man.\"</td>\n",
              "      <td>clickbait</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32a7abbe-4ca4-44d0-8067-f5eec66b958c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32a7abbe-4ca4-44d0-8067-f5eec66b958c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32a7abbe-4ca4-44d0-8067-f5eec66b958c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos si existen valores vacios en test \n",
        "print(\"Hay {} valores vacíos en postText y {} valores vacíos en las etiquetas en los datos\".format(np.sum(test.isnull())[0],\n",
        "                                                                                                   np.sum(test.isnull())[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8XqwbRO2W7u",
        "outputId": "b5e8a99a-3b8c-46ce-a82c-8eaee476fca5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hay 1 valores vacíos en postText y 0 valores vacíos en las etiquetas en los datos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = test.dropna()"
      ],
      "metadata": {
        "id": "FXmffcns2zhM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos  que se han eliminado\n",
        "print(\"Hay {} valores vacíos en postText y {} valores vacíos en las etiquetas en los datos\".format(np.sum(test.isnull())[0],\n",
        "                                                                                                   np.sum(test.isnull())[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvVAMTiz2zkj",
        "outputId": "6345fd28-ba19-459e-ff04-4ca21f98a8ab"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hay 0 valores vacíos en postText y 0 valores vacíos en las etiquetas en los datos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos cuantas etiquetas hay de cada clase, para ver si está balanceado o no\n",
        "pd.value_counts(train['truthClass'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjVn4igH29Ku",
        "outputId": "66883c3f-df01-4e1e-8e73-81894685a085"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no-clickbait    14544\n",
              "clickbait        4537\n",
              "Name: truthClass, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que no está balanceado, esto implica que podrá darnos problemas de entrenamiento, pero esto sucede en la mayoría de casos. \n",
        "A continuación se muestra un gráfico de dicho desvalanceo."
      ],
      "metadata": {
        "id": "5Lnk-x573e9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "ax, fig = plt.subplots()\n",
        "etiquetas = pd.value_counts(train['truthClass']) # Número de etiquetas de cada clase\n",
        "etiquetas.plot(kind= 'bar', color= [\"pink\", \"turquoise\"]) # bar es que es tipo histograma\n",
        "plt.title('Gráfico de barras etiquetas Reviews')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "mnXKyT563v_z",
        "outputId": "52ab40b5-bd44-4de7-f18a-187e55be3e5d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['truthClass'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aROnYhC3keXJ",
        "outputId": "bb10ac7f-a742-45f2-c14d-c1fb0608d5cf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['no-clickbait', 'clickbait'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambio las etiquetas de los datos, donde antes era no-clickbait ahora será 0 y clickbait será 1.\n",
        "train['truthClass'] = train['truthClass'].map({'no-clickbait':0, 'clickbait':1}, na_action=None)\n",
        "test['truthClass'] = test['truthClass'].map({'no-clickbait':0, 'clickbait':1}, na_action=None)"
      ],
      "metadata": {
        "id": "1gi0Mc_y4V7V"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "KrqZBka84pLP",
        "outputId": "bc239b4c-d8a0-4c9c-82dc-726d999caeff"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            postText  truthClass\n",
              "0  UK’s response to modern slavery leaving victim...           0\n",
              "1                                       this is good           1\n",
              "2  The \"forgotten\" Trump roast: Relive his brutal...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6ad6b8d-9358-4f08-aecc-f4520e559fd7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>postText</th>\n",
              "      <th>truthClass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UK’s response to modern slavery leaving victim...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this is good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6ad6b8d-9358-4f08-aecc-f4520e559fd7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6ad6b8d-9358-4f08-aecc-f4520e559fd7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6ad6b8d-9358-4f08-aecc-f4520e559fd7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creo una lista con las etiquetas\n",
        "target_names = ['no-clickbait', 'clickbait']"
      ],
      "metadata": {
        "id": "BReITydU4unX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hago varias transformaciones para obtener el formato que necesito\n",
        "train_texts = train['postText'].to_list()\n",
        "valid_texts = test['postText'].to_list()\n",
        "train_labels = train['truthClass'].to_list()\n",
        "valid_labels = test['truthClass'].to_list()"
      ],
      "metadata": {
        "id": "yt2PZ9fM4zio"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = np.array(train_labels,)\n",
        "valid_labels = np.array(valid_labels,)"
      ],
      "metadata": {
        "id": "ML8smDZX4zlG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar el modelo que vamos a usar es el \"bert-base-uncased\", el cual es un modelo preentrenado en inglés."
      ],
      "metadata": {
        "id": "S_inVUXuttry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name1 = \"bert-base-uncased\""
      ],
      "metadata": {
        "id": "g0VrCdUFeF0G"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero dividiremos nuestras oraciones en tokens, es decir, en unidades de texto mínimas, todas las palabras así como determinantes, preposiciones, iconos si los hubiese, etcetera."
      ],
      "metadata": {
        "id": "sVvAfoS5u8Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos un tokenizador para poder dividir las secuencias en tokens\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name1, do_lower_case=True)\n",
        "# do_lower_case = True para escribir en minúsculas todo el texto "
      ],
      "metadata": {
        "id": "7IvpNBkLkeRe"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora usamos el tokenizador para nuestro corpus.\n",
        "train_encodings = tokenizer(train_texts, padding=True)\n",
        "valid_encodings = tokenizer(valid_texts, padding=True)\n",
        "# Puesto que no he usado max_length tomará aquel texto que tenga longitud maxima\n",
        "# por ello padding = True para que rellene con fichas vacías aquellos que son menores que diche longitud"
      ],
      "metadata": {
        "id": "GUtB7WtU4znd"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsGroupsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# convierte los datos tokenizados en un torch dataset\n",
        "# ya que para usar transformers se necesita formato torch \n",
        "train_dataset = NewsGroupsDataset(train_encodings, train_labels)\n",
        "valid_dataset = NewsGroupsDataset(valid_encodings, valid_labels)"
      ],
      "metadata": {
        "id": "p-Onkjoq5Q3w"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargo el modelo y sus pesos pre-entrenados\n",
        "model1 = BertForSequenceClassification.from_pretrained(model_name1, num_labels=len(target_names))\n",
        "# num_labels, es el número de clases que tiene nuetra variable objetivo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKdwCSA95XFY",
        "outputId": "966b837e-755c-442b-c77c-073b87fd7cd4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para calcuular la métrica que deseamos, en este caso solo la accuracy\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  # calcula la accuraccy \n",
        "  acc = accuracy_score(labels, preds)\n",
        "  # calcula la matriz de confusión\n",
        "  recall = recall_score(labels, preds)\n",
        "  precision = precision_score(labels, preds)\n",
        "  f1 = f1_score(labels, preds)\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "      'recall': recall,\n",
        "      'precision' : precision,\n",
        "      'f1': f1,\n",
        "  }"
      ],
      "metadata": {
        "id": "a6L1gojD7CBa"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para calcuular la métrica que deseamos, en este caso solo la accuracy\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def matriz_confusion(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "\n",
        "  TN = confusion_matrix(labels, preds)[0][0]\n",
        "  FP = confusion_matrix(labels, preds)[0][1]\n",
        "  FN = confusion_matrix(labels, preds)[1][0]\n",
        "  TP = confusion_matrix(labels, preds)[1][1]\n",
        "  \n",
        "  return {\n",
        "      'TN': TN,\n",
        "      'FP': FP,\n",
        "      'FN': FN,\n",
        "      'TP': TP,\n",
        "      \n",
        "  }"
      ],
      "metadata": {
        "id": "H4MxEU8QRQnB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Especificamos nuestros argumentos de entrenamiento\n",
        "training_args1 = TrainingArguments(\n",
        "    output_dir='./results',          # directorio de salida\n",
        "    num_train_epochs=1,              # número de veces que se repiten los datos de entrenamiento\n",
        "    per_device_train_batch_size=4,  # tamaño del lote durante entrenamiento\n",
        "    per_device_eval_batch_size=8,   # tamaño del lote para evaluación\n",
        "    warmup_steps=100,                # número de pasos para la tasa de aprendizaje\n",
        "    weight_decay=0.01,               # evita que los pesos se hagan demasiado grandes\n",
        "    logging_dir='./logs',            # directorio para guardar registros\n",
        "    load_best_model_at_end=True,     # carga el mejor modelo cuando finaliza el entrenamiento (metrica por defecto es loss)\n",
        "    # pero puede especificar `metric_for_best_model` para cambiar a accuracy u otra métrica.\n",
        "    logging_steps=800,               # registrar y guardar pesos cada logging_steps\n",
        "    save_steps=800,\n",
        "    evaluation_strategy=\"steps\",     # evaluar cada `logging_steps`\n",
        ")"
      ],
      "metadata": {
        "id": "h57CZa5L8Zj4"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer1 = Trainer(\n",
        "    model=model1,                         # modelo a entrenar\n",
        "    args=training_args1,                  # argumentos sobre los que se va a entrenar\n",
        "    train_dataset=train_dataset,         # dataset de entrenamiento\n",
        "    eval_dataset=valid_dataset,          # dataset de evaluación\n",
        "    compute_metrics=compute_metrics,     # calcula las métricas de intereés\n",
        ")"
      ],
      "metadata": {
        "id": "UyFV_niZ8Zm5"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "trainer1.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4k-aRDpC8ZpS",
        "outputId": "c33816f0-ee50-40ae-a02f-0eea602f5593"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 19081\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4771\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4771' max='4771' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4771/4771 14:28, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.535800</td>\n",
              "      <td>0.464216</td>\n",
              "      <td>0.853181</td>\n",
              "      <td>0.513130</td>\n",
              "      <td>0.779111</td>\n",
              "      <td>0.618747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.546800</td>\n",
              "      <td>0.421065</td>\n",
              "      <td>0.845033</td>\n",
              "      <td>0.709040</td>\n",
              "      <td>0.653179</td>\n",
              "      <td>0.679964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.504800</td>\n",
              "      <td>0.421549</td>\n",
              "      <td>0.820267</td>\n",
              "      <td>0.770160</td>\n",
              "      <td>0.585926</td>\n",
              "      <td>0.665529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.501800</td>\n",
              "      <td>0.483641</td>\n",
              "      <td>0.861490</td>\n",
              "      <td>0.604462</td>\n",
              "      <td>0.750433</td>\n",
              "      <td>0.669584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.453900</td>\n",
              "      <td>0.449530</td>\n",
              "      <td>0.857983</td>\n",
              "      <td>0.541018</td>\n",
              "      <td>0.779899</td>\n",
              "      <td>0.638858</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-800\n",
            "Configuration saved in ./results/checkpoint-800/config.json\n",
            "Model weights saved in ./results/checkpoint-800/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1600\n",
            "Configuration saved in ./results/checkpoint-1600/config.json\n",
            "Model weights saved in ./results/checkpoint-1600/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-2400\n",
            "Configuration saved in ./results/checkpoint-2400/config.json\n",
            "Model weights saved in ./results/checkpoint-2400/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-3200\n",
            "Configuration saved in ./results/checkpoint-3200/config.json\n",
            "Model weights saved in ./results/checkpoint-3200/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Configuration saved in ./results/checkpoint-4000/config.json\n",
            "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-1600 (score: 0.42106515169143677).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4771, training_loss=0.5015093632100188, metrics={'train_runtime': 868.6062, 'train_samples_per_second': 21.967, 'train_steps_per_second': 5.493, 'total_flos': 1019773228362720.0, 'train_loss': 0.5015093632100188, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'Training loss' indica qué tan bien se ajusta el modelo a los datos de entrenamiento, mientras que 'Validation loss' indica qué tan bien se ajusta el modelo a los datos nuevos. Estos valores tienen que decrecer puesto que estos algoritmos se basan en el descenso de gradiente, no se consigue gran mejora con respecto a la primera iteración."
      ],
      "metadata": {
        "id": "i1_FvoJT9Ma8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos el mejor modelo obtenido después del entrenamiento\n",
        "trainer1.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "2kYVAwVZ8ZsM",
        "outputId": "78ccd3a9-b159-4176-85fa-4b02a8c6f40f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2317' max='2317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2317/2317 00:55]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 1.0,\n",
              " 'eval_accuracy': 0.8450331840500729,\n",
              " 'eval_f1': 0.6799643414308001,\n",
              " 'eval_loss': 0.42106515169143677,\n",
              " 'eval_precision': 0.653179190751445,\n",
              " 'eval_recall': 0.7090402045084825,\n",
              " 'eval_runtime': 55.527,\n",
              " 'eval_samples_per_second': 333.766,\n",
              " 'eval_steps_per_second': 41.727}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La evaluación se realiza sobre el mejor modelo obtenido anteriormente.\n",
        "\n",
        "Hemos evaluado distintas métricas, como se trata de un dataset con datos muy desbalanceados no nos bastará con mirar la accuracy, pues esta medida solo tiene en cuenta el número de aciertos, pero esto para clases desbalanceadas no es lo idóneo, puesto que puede predcir a la perfección la clase mayoritaria, pero por el contrario no predecir en absoluto la clase minoritaria.\n",
        "Esto no nos sirve porque un modelo que nos diga que todas las noticias no son clickbait no nos sirve en absoluto. \n",
        "\n",
        "Tendríamos que tener en cuenta recall y precision.\n",
        "\n",
        "Si tenemos:\n",
        "\n",
        "* Alta precision y alto recall, el modelo maneja perfectamente esa clase.\n",
        "* Alta precision y bajo recall el modelo no detecta la clase muy bien, pero cuando lo hace es confiable.\n",
        "* Baja precision y alto recall, detecta bien la clase, pero también incluye muestras de la otra clase.\n",
        "* Baja precision y bajo recall el modelo no logra clasificar la clase correctamente.\n",
        "\n",
        "En este caso hemos obtenido con el mejor modelo:\n",
        "\n",
        "* precision =  0.653179190751445\n",
        "* recall = 0.7090402045084825\n",
        "\n",
        "Vemos que no son valores extremadamente bajos, pero tampoco son altos, por lo que nuestro modelo no está pudiendo clasificar la clase tan bien como desearíamos."
      ],
      "metadata": {
        "id": "-p6Q_UhFXbxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer5 = Trainer(\n",
        "    model=model1,                         # modelo a entrenar\n",
        "    args=training_args1,                  # argumentos sobre los que se va a entrenar\n",
        "    train_dataset=train_dataset,         # dataset de entrenamiento\n",
        "    eval_dataset=valid_dataset,          # dataset de evaluación\n",
        "    compute_metrics=matriz_confusion,     # calcula las métricas de intereés\n",
        ")"
      ],
      "metadata": {
        "id": "tMH_1eLWWpNl"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "trainer5.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HO4VAmQkWpUF",
        "outputId": "494f06f3-4150-4ff5-b799-f2f1c249d5e2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 19081\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4771\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4771' max='4771' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4771/4771 14:37, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Tn</th>\n",
              "      <th>Fp</th>\n",
              "      <th>Fn</th>\n",
              "      <th>Tp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.489800</td>\n",
              "      <td>0.710253</td>\n",
              "      <td>12594</td>\n",
              "      <td>1636</td>\n",
              "      <td>1318</td>\n",
              "      <td>2985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.464100</td>\n",
              "      <td>0.616323</td>\n",
              "      <td>13600</td>\n",
              "      <td>630</td>\n",
              "      <td>2063</td>\n",
              "      <td>2240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.522900</td>\n",
              "      <td>0.456129</td>\n",
              "      <td>11726</td>\n",
              "      <td>2504</td>\n",
              "      <td>857</td>\n",
              "      <td>3446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.500400</td>\n",
              "      <td>0.516642</td>\n",
              "      <td>13725</td>\n",
              "      <td>505</td>\n",
              "      <td>2329</td>\n",
              "      <td>1974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.455200</td>\n",
              "      <td>0.423297</td>\n",
              "      <td>13415</td>\n",
              "      <td>815</td>\n",
              "      <td>1752</td>\n",
              "      <td>2551</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-800\n",
            "Configuration saved in ./results/checkpoint-800/config.json\n",
            "Model weights saved in ./results/checkpoint-800/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1600\n",
            "Configuration saved in ./results/checkpoint-1600/config.json\n",
            "Model weights saved in ./results/checkpoint-1600/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-2400\n",
            "Configuration saved in ./results/checkpoint-2400/config.json\n",
            "Model weights saved in ./results/checkpoint-2400/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-3200\n",
            "Configuration saved in ./results/checkpoint-3200/config.json\n",
            "Model weights saved in ./results/checkpoint-3200/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Configuration saved in ./results/checkpoint-4000/config.json\n",
            "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-4000 (score: 0.42329713702201843).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4771, training_loss=0.4858122173781866, metrics={'train_runtime': 878.3682, 'train_samples_per_second': 21.723, 'train_steps_per_second': 5.432, 'total_flos': 1019773228362720.0, 'train_loss': 0.4858122173781866, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos el mejor modelo obtenido después del entrenamiento\n",
        "trainer5.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "mC3Fs3w9WpdP",
        "outputId": "801b7371-a364-4448-81c2-b241402e7c8d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2317' max='2317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2317/2317 00:55]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 1.0,\n",
              " 'eval_FN': 1752,\n",
              " 'eval_FP': 815,\n",
              " 'eval_TN': 13415,\n",
              " 'eval_TP': 2551,\n",
              " 'eval_loss': 0.42329713702201843,\n",
              " 'eval_runtime': 55.1235,\n",
              " 'eval_samples_per_second': 336.209,\n",
              " 'eval_steps_per_second': 42.033}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De esta manera hemos obtenido la matriz de confusión, siendo, FN falsos negativos, FP falsos positivos, TN verdaderos negativos y TP verdaderos positivos."
      ],
      "metadata": {
        "id": "0IS4AnckaA9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Especificamos nuevos argumentos de entrenamiento\n",
        "training_args2 = TrainingArguments(\n",
        "    output_dir='./results',          # directorio de salida\n",
        "    num_train_epochs=2,              # número de veces que se repiten los datos de entrenamiento\n",
        "    per_device_train_batch_size=8,  # tamaño del lote durante entrenamiento\n",
        "    per_device_eval_batch_size=8,   # tamaño del lote para evaluación\n",
        "    warmup_steps=200,                # número de pasos para la tasa de aprendizaje\n",
        "    weight_decay=0.01,               # evita que los pesos se hagan demasiado grandes\n",
        "    logging_dir='./logs',            # directorio para guardar registros\n",
        "    load_best_model_at_end=True,     # carga el mejor modelo cuando finaliza el entrenamiento (metrica por defecto es loss)\n",
        "    # pero puede especificar `metric_for_best_model` para cambiar a accuracy u otra métrica.\n",
        "    logging_steps=600,               # registrar y guardar pesos cada logging_steps\n",
        "    save_steps=600,\n",
        "    evaluation_strategy=\"steps\",     # evaluar cada `logging_steps`\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpHLrt-j8ZvG",
        "outputId": "f961a7b0-43c5-428d-d89b-dff88bad5d1c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 600\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2 = Trainer(\n",
        "    model=model1,                         # modelo a entrenar\n",
        "    args=training_args2,                  # argumentos sobre los que se va a entrenar\n",
        "    train_dataset=train_dataset,         # dataset de entrenamiento\n",
        "    eval_dataset=valid_dataset,          # dataset de evaluación\n",
        "    compute_metrics=compute_metrics,     # calcula las métricas de intereés\n",
        ")"
      ],
      "metadata": {
        "id": "759GiXdUnEvZ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "trainer2.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EyS5ptx1MnQs",
        "outputId": "fc0a2ef2-2bec-4470-cc44-f56e3dbd4848"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 19081\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4772\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4772' max='4772' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4772/4772 20:54, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.348300</td>\n",
              "      <td>0.516784</td>\n",
              "      <td>0.839745</td>\n",
              "      <td>0.742040</td>\n",
              "      <td>0.631902</td>\n",
              "      <td>0.682557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.395900</td>\n",
              "      <td>0.385027</td>\n",
              "      <td>0.835051</td>\n",
              "      <td>0.743435</td>\n",
              "      <td>0.620924</td>\n",
              "      <td>0.676679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.405800</td>\n",
              "      <td>0.428900</td>\n",
              "      <td>0.843307</td>\n",
              "      <td>0.697885</td>\n",
              "      <td>0.651834</td>\n",
              "      <td>0.674074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.400800</td>\n",
              "      <td>0.434161</td>\n",
              "      <td>0.852102</td>\n",
              "      <td>0.553567</td>\n",
              "      <td>0.743910</td>\n",
              "      <td>0.634777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.347200</td>\n",
              "      <td>0.400090</td>\n",
              "      <td>0.847084</td>\n",
              "      <td>0.506856</td>\n",
              "      <td>0.753889</td>\n",
              "      <td>0.606170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.347400</td>\n",
              "      <td>0.380194</td>\n",
              "      <td>0.857497</td>\n",
              "      <td>0.549849</td>\n",
              "      <td>0.770684</td>\n",
              "      <td>0.641801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.336800</td>\n",
              "      <td>0.431259</td>\n",
              "      <td>0.859602</td>\n",
              "      <td>0.624216</td>\n",
              "      <td>0.731681</td>\n",
              "      <td>0.673689</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-600\n",
            "Configuration saved in ./results/checkpoint-600/config.json\n",
            "Model weights saved in ./results/checkpoint-600/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1200\n",
            "Configuration saved in ./results/checkpoint-1200/config.json\n",
            "Model weights saved in ./results/checkpoint-1200/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1800\n",
            "Configuration saved in ./results/checkpoint-1800/config.json\n",
            "Model weights saved in ./results/checkpoint-1800/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-2400\n",
            "Configuration saved in ./results/checkpoint-2400/config.json\n",
            "Model weights saved in ./results/checkpoint-2400/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Configuration saved in ./results/checkpoint-3000/config.json\n",
            "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-3600\n",
            "Configuration saved in ./results/checkpoint-3600/config.json\n",
            "Model weights saved in ./results/checkpoint-3600/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-4200\n",
            "Configuration saved in ./results/checkpoint-4200/config.json\n",
            "Model weights saved in ./results/checkpoint-4200/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-3600 (score: 0.3801935315132141).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4772, training_loss=0.3657424683742731, metrics={'train_runtime': 1255.0844, 'train_samples_per_second': 30.406, 'train_steps_per_second': 3.802, 'total_flos': 2039546456725440.0, 'train_loss': 0.3657424683742731, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos el mejor modelo obtenido después del entrenamiento\n",
        "trainer2.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "lY9ICdg6Mr7h",
        "outputId": "921dff34-0f3a-4c88-d6e1-16aaa383c975"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2317' max='2317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2317/2317 00:54]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_accuracy': 0.8574974370042626,\n",
              " 'eval_f1': 0.6418011664180118,\n",
              " 'eval_loss': 0.3801935315132141,\n",
              " 'eval_precision': 0.7706840390879479,\n",
              " 'eval_recall': 0.5498489425981873,\n",
              " 'eval_runtime': 54.9343,\n",
              " 'eval_samples_per_second': 337.367,\n",
              " 'eval_steps_per_second': 42.178}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta ocasión al variar los parámetros hemos tardado más tiempo en el entrenamiento.\n",
        "Al aumentar el número de 'epoch', se obtiene un mejor entrenamiento.\n",
        "Se ha disminuido el número de pasos tras los que se evalua y guarda el modelo, disminuyendo, hacemos que se evalúe y guarde más veces el modelo, ya que lo hace cada menos pasos, debido a esto también se ha aumentado el tiempo de cómputo.\n",
        "\n",
        "Se puede comprobar como variando los parámetros podríamos seguir mejorando el modelo, para ello deberíamos aumentar el número de 'epoch', así como aumentar el tamaño del batch y también disminuir aún más los pasos tras los que se evalua y guarda el modelo, pero debido a la falta de GPU y disponibilidad de google colab esto no ha sido posible."
      ],
      "metadata": {
        "id": "pvhnyUovxLPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta ocasión hemos obtenido:\n",
        "\n",
        "* precision =  0.7706840390879479\n",
        "* recall =  0.5498489425981873\n",
        "\n",
        "Por lo que hemos conseguido mejorar el modelo en cuestión de recall pero empeorarlo en cuestión de precision.\n",
        "\n",
        "Como ambas medidas no son demasiado altas, seguiríamos opinando que el modelo realmente no detecta bien la clase."
      ],
      "metadata": {
        "id": "rRhi9WbX05b3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer6 = Trainer(\n",
        "    model=model1,                         # modelo a entrenar\n",
        "    args=training_args2,                  # argumentos sobre los que se va a entrenar\n",
        "    train_dataset=train_dataset,         # dataset de entrenamiento\n",
        "    eval_dataset=valid_dataset,          # dataset de evaluación\n",
        "    compute_metrics=matriz_confusion,     # calcula las métricas de intereés\n",
        ")"
      ],
      "metadata": {
        "id": "5RDBZyN_b3gm"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer6.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AbvM1bGVXB4O",
        "outputId": "eb5a8055-5eb5-46a1-cbc2-82baf6a4ffc2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 19081\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4772\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4772' max='4772' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4772/4772 20:53, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Tn</th>\n",
              "      <th>Fp</th>\n",
              "      <th>Fn</th>\n",
              "      <th>Tp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.269300</td>\n",
              "      <td>0.452318</td>\n",
              "      <td>12852</td>\n",
              "      <td>1378</td>\n",
              "      <td>1396</td>\n",
              "      <td>2907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.387900</td>\n",
              "      <td>0.428846</td>\n",
              "      <td>12917</td>\n",
              "      <td>1313</td>\n",
              "      <td>1396</td>\n",
              "      <td>2907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.369700</td>\n",
              "      <td>0.437188</td>\n",
              "      <td>13225</td>\n",
              "      <td>1005</td>\n",
              "      <td>1672</td>\n",
              "      <td>2631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.385000</td>\n",
              "      <td>0.443489</td>\n",
              "      <td>13339</td>\n",
              "      <td>891</td>\n",
              "      <td>1823</td>\n",
              "      <td>2480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.367800</td>\n",
              "      <td>0.464438</td>\n",
              "      <td>13531</td>\n",
              "      <td>699</td>\n",
              "      <td>2061</td>\n",
              "      <td>2242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.356200</td>\n",
              "      <td>0.460367</td>\n",
              "      <td>13093</td>\n",
              "      <td>1137</td>\n",
              "      <td>1516</td>\n",
              "      <td>2787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.362100</td>\n",
              "      <td>0.437226</td>\n",
              "      <td>13089</td>\n",
              "      <td>1141</td>\n",
              "      <td>1554</td>\n",
              "      <td>2749</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-600\n",
            "Configuration saved in ./results/checkpoint-600/config.json\n",
            "Model weights saved in ./results/checkpoint-600/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1200\n",
            "Configuration saved in ./results/checkpoint-1200/config.json\n",
            "Model weights saved in ./results/checkpoint-1200/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1800\n",
            "Configuration saved in ./results/checkpoint-1800/config.json\n",
            "Model weights saved in ./results/checkpoint-1800/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-2400\n",
            "Configuration saved in ./results/checkpoint-2400/config.json\n",
            "Model weights saved in ./results/checkpoint-2400/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Configuration saved in ./results/checkpoint-3000/config.json\n",
            "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-3600\n",
            "Configuration saved in ./results/checkpoint-3600/config.json\n",
            "Model weights saved in ./results/checkpoint-3600/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-4200\n",
            "Configuration saved in ./results/checkpoint-4200/config.json\n",
            "Model weights saved in ./results/checkpoint-4200/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-1200 (score: 0.428846150636673).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4772, training_loss=0.3555691472043136, metrics={'train_runtime': 1253.466, 'train_samples_per_second': 30.445, 'train_steps_per_second': 3.807, 'total_flos': 2039546456725440.0, 'train_loss': 0.3555691472043136, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer6.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "PdtQtWjFXB7-",
        "outputId": "1f956c5a-8319-4e9b-d23c-53b778a54b14"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2317' max='2317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2317/2317 00:54]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_FN': 1396,\n",
              " 'eval_FP': 1313,\n",
              " 'eval_TN': 12917,\n",
              " 'eval_TP': 2907,\n",
              " 'eval_loss': 0.428846150636673,\n",
              " 'eval_runtime': 54.6952,\n",
              " 'eval_samples_per_second': 338.841,\n",
              " 'eval_steps_per_second': 42.362}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados anteriores:\n",
        "* FN: 1752\n",
        "* FP: 815\n",
        "* TN: 13415\n",
        "* TP: 2551\n",
        "\n",
        "Resultados actuales:\n",
        "* FN: 1396\n",
        "* FP: 1313\n",
        "* TN: 12917\n",
        "* TP: 2907\n",
        "\n",
        "Nuestras clases están desbalanceadas, teniendo en total de 14544 ceros y 4537 unos.\n",
        "\n",
        "Hay ocasiones en las que se preferirá predecir mejor los ceros o predecir mejor los unos, en esta ocasión como la clase minoritaria es la clase 1, queremos que esta clase nos la acierte mejor, por la que preferiremos acertar mejor los positivos. Preferimos más verdaderos positivos, por lo que el modelo con los segundos argumentos será el mejor en esta ocasión, ya que pasa de 2551 a acertar 2907 positivos."
      ],
      "metadata": {
        "id": "3pfQRdDLbIGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considero que lo solicitado ha sido realizado obteniendo bastante buenos resultados, ya que se pidió un modelo de detección de clickbait en tweets, utilizando la técnica de fine-tuning de un modelo pre-entrenado de tipo BERT y se ha realizado correctamente.\n",
        "\n",
        "Aunque me hubiese gustado poder probar más modelos, así como poder variar más los parámetros para intentar conseguir mejorares y conseguir mejores resultados, cosa que no ha podido realizarse debido a las disponibilidades de GPU de google colab free."
      ],
      "metadata": {
        "id": "PRUOdQRIbgpN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODIFICANDO DATASET**"
      ],
      "metadata": {
        "id": "4995S0cfd5i-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trabajando con el dataset tal cuál podríamos intentar mejorar los valores tuneando los parámetros y así intentar obtener mejores resultados, pero esto puede llegar a ser bastante complicado de conseguir debido al desbalanceo entre clases.\n",
        "\n",
        "Para poder solucionar este problema, lo que tendríamos que realizar es alguna de las técnicas para balancear el dataset.\n",
        "\n",
        "Existen diferentes técnicas para ello, basandose algunas de ellas en la creación de nuevos datos para poder igualar las clases, o el caso contrario, el cual se trataría de eliminar datos de la clase mayoritaria para así poder obtener unn dataset balanceado."
      ],
      "metadata": {
        "id": "pAiZkN-p2MDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ordeno el dataset dejando a la clase mayoritaria al final del dataset, para así poder eliminar los últimos datos de dicho dataset y ya estaría balanceado."
      ],
      "metadata": {
        "id": "9trMzyb9eYGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenamos el dataset train\n",
        "train_ordered = train.sort_values('truthClass',ascending = False, ignore_index = True)\n",
        "train_ordered.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "5swC2U4B22Ta",
        "outputId": "483bcce7-d5e1-42d4-827e-d606146096d6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             postText  truthClass\n",
              "0   So when exactly does the New Year begin in space?           1\n",
              "1                  Time to start doing your homework:           1\n",
              "2   The earbuds of the future will let you control...           1\n",
              "3   So the (basically) official Arthur Twitter jus...           1\n",
              "4   They were hoping to get to the US -- and then ...           1\n",
              "..                                                ...         ...\n",
              "95        Is this the mobile home for the apocalypse?           1\n",
              "96  30 years later, the creepy Max Headroom broadc...           1\n",
              "97  Here are the best titles coming to Netflix in ...           1\n",
              "98  Women flood Twitter with stories of the first ...           1\n",
              "99  The #journalist, reportedly, even shared detai...           1\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b56cac76-5023-46f1-86d2-414fe25ec1b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>postText</th>\n",
              "      <th>truthClass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So when exactly does the New Year begin in space?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Time to start doing your homework:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The earbuds of the future will let you control...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>So the (basically) official Arthur Twitter jus...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>They were hoping to get to the US -- and then ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Is this the mobile home for the apocalypse?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>30 years later, the creepy Max Headroom broadc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Here are the best titles coming to Netflix in ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Women flood Twitter with stories of the first ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>The #journalist, reportedly, even shared detai...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b56cac76-5023-46f1-86d2-414fe25ec1b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b56cac76-5023-46f1-86d2-414fe25ec1b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b56cac76-5023-46f1-86d2-414fe25ec1b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.value_counts(train_ordered['truthClass'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzT5O2fb3lBY",
        "outputId": "3abd3e13-a26d-4a10-eb5f-42cbd706f681"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    14544\n",
              "1     4537\n",
              "Name: truthClass, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ordered"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kmCWZSYa7aEi",
        "outputId": "a91727e5-1d40-4e9b-9b32-0ab1c60e5255"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                postText  truthClass\n",
              "0      So when exactly does the New Year begin in space?           1\n",
              "1                     Time to start doing your homework:           1\n",
              "2      The earbuds of the future will let you control...           1\n",
              "3      So the (basically) official Arthur Twitter jus...           1\n",
              "4      They were hoping to get to the US -- and then ...           1\n",
              "...                                                  ...         ...\n",
              "19076  \"Tasty the Cookbook\" has been a huge hit for @...           0\n",
              "19077  Five races to watch during Sunday’s Golden Glo...           0\n",
              "19078  Queen appears in public for first time in a mo...           0\n",
              "19079  The long, hard road to repealing Obamacare is ...           0\n",
              "19080  Richard Sherman weighs in on Cam Newton’s stru...           0\n",
              "\n",
              "[19081 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98618deb-81fd-4abe-84e5-53ce55bfb642\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>postText</th>\n",
              "      <th>truthClass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So when exactly does the New Year begin in space?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Time to start doing your homework:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The earbuds of the future will let you control...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>So the (basically) official Arthur Twitter jus...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>They were hoping to get to the US -- and then ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19076</th>\n",
              "      <td>\"Tasty the Cookbook\" has been a huge hit for @...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19077</th>\n",
              "      <td>Five races to watch during Sunday’s Golden Glo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19078</th>\n",
              "      <td>Queen appears in public for first time in a mo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19079</th>\n",
              "      <td>The long, hard road to repealing Obamacare is ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19080</th>\n",
              "      <td>Richard Sherman weighs in on Cam Newton’s stru...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19081 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98618deb-81fd-4abe-84e5-53ce55bfb642')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98618deb-81fd-4abe-84e5-53ce55bfb642 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98618deb-81fd-4abe-84e5-53ce55bfb642');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_balanceado = train_ordered.drop(range(9073,19080),axis=0)"
      ],
      "metadata": {
        "id": "crxTqPOJ32_W"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_balanceado"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DJ8lWdvf6bY0",
        "outputId": "c5bf4ff0-f8a4-4540-c89a-81e67f0ab310"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                postText  truthClass\n",
              "0      So when exactly does the New Year begin in space?           1\n",
              "1                     Time to start doing your homework:           1\n",
              "2      The earbuds of the future will let you control...           1\n",
              "3      So the (basically) official Arthur Twitter jus...           1\n",
              "4      They were hoping to get to the US -- and then ...           1\n",
              "...                                                  ...         ...\n",
              "9069   NFL denies barring Lady Gaga from talking poli...           0\n",
              "9070   White House press secretary Josh Earnest: The ...           0\n",
              "9071   Seeing a lot of pink hats today? The \"Pussyhat...           0\n",
              "9072   People with high emotional intelligence are ma...           0\n",
              "19080  Richard Sherman weighs in on Cam Newton’s stru...           0\n",
              "\n",
              "[9074 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa42f759-76e7-43e9-b9ae-2227227e3214\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>postText</th>\n",
              "      <th>truthClass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So when exactly does the New Year begin in space?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Time to start doing your homework:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The earbuds of the future will let you control...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>So the (basically) official Arthur Twitter jus...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>They were hoping to get to the US -- and then ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9069</th>\n",
              "      <td>NFL denies barring Lady Gaga from talking poli...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9070</th>\n",
              "      <td>White House press secretary Josh Earnest: The ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9071</th>\n",
              "      <td>Seeing a lot of pink hats today? The \"Pussyhat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9072</th>\n",
              "      <td>People with high emotional intelligence are ma...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19080</th>\n",
              "      <td>Richard Sherman weighs in on Cam Newton’s stru...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9074 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa42f759-76e7-43e9-b9ae-2227227e3214')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa42f759-76e7-43e9-b9ae-2227227e3214 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa42f759-76e7-43e9-b9ae-2227227e3214');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.value_counts(train_balanceado['truthClass'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-SBopHV4r4-",
        "outputId": "7ce839a4-738b-43a0-fc08-83f264c68b3a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4537\n",
              "0    4537\n",
              "Name: truthClass, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora ya tenemos un datset totalmente balanceado, por lo que procederemos a realizar los mismo cálculos realizados anteriormente.\n",
        "\n",
        "Al conjunto de test no le realizamos de balanceo, pues no es necesario, ya que con ellos no estamos entrenando el modelo, solo lo evaluaríamos."
      ],
      "metadata": {
        "id": "vcUyTG0L8OMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hago varias transformaciones para obtener el formato que necesito\n",
        "train_texts = train_balanceado['postText'].to_list()\n",
        "train_labels = train_balanceado['truthClass'].to_list()"
      ],
      "metadata": {
        "id": "njMk9-TH6DUi"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = np.array(train_labels,)"
      ],
      "metadata": {
        "id": "90GJY1kI9Jv6"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizo todos los pasos de nuevo, pero para nuestro nuevo conjunto de entrenamiento."
      ],
      "metadata": {
        "id": "HMAuNSu7ASFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora usamos el tokenizador para nuestro corpus.\n",
        "train_encodings = tokenizer(train_texts, padding=True)\n",
        "valid_encodings = tokenizer(valid_texts, padding=True)\n",
        "# Puesto que no he usado max_length tomará aquel texto que tenga longitud maxima\n",
        "# por ello padding = True para que rellene con fichas vacías aquellos que son menores que diche longitud"
      ],
      "metadata": {
        "id": "bKMSo7_79Pkl"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convierte los datos tokenizados en un torch dataset\n",
        "# ya que para usar transformers se necesita formato torch \n",
        "train_dataset = NewsGroupsDataset(train_encodings, train_labels)\n",
        "valid_dataset = NewsGroupsDataset(valid_encodings, valid_labels)"
      ],
      "metadata": {
        "id": "TUv7Iv5k9X2Z"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer3 = Trainer(\n",
        "    model=model1,                         # modelo a entrenar\n",
        "    args=training_args1,                  # argumentos sobre los que se va a entrenar\n",
        "    train_dataset=train_dataset,         # dataset de entrenamiento\n",
        "    eval_dataset=valid_dataset,          # dataset de evaluación\n",
        "    compute_metrics=compute_metrics,     # calcula las métricas de intereés\n",
        ")"
      ],
      "metadata": {
        "id": "lDIdbsle9fkY"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "trainer3.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "Xa-P2rLB9rhC",
        "outputId": "c0fa5626-3d00-4eed-d7af-e23927506a17"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 9074\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2269\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2269' max='2269' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2269/2269 06:31, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.537900</td>\n",
              "      <td>0.557986</td>\n",
              "      <td>0.845789</td>\n",
              "      <td>0.652103</td>\n",
              "      <td>0.673386</td>\n",
              "      <td>0.662574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.562400</td>\n",
              "      <td>0.610267</td>\n",
              "      <td>0.731290</td>\n",
              "      <td>0.881246</td>\n",
              "      <td>0.459024</td>\n",
              "      <td>0.603629</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-800\n",
            "Configuration saved in ./results/checkpoint-800/config.json\n",
            "Model weights saved in ./results/checkpoint-800/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1600\n",
            "Configuration saved in ./results/checkpoint-1600/config.json\n",
            "Model weights saved in ./results/checkpoint-1600/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-800 (score: 0.557986319065094).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2269, training_loss=0.5471066054188244, metrics={'train_runtime': 391.8014, 'train_samples_per_second': 23.16, 'train_steps_per_second': 5.791, 'total_flos': 484954786130880.0, 'train_loss': 0.5471066054188244, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos el mejor modelo obtenido después del entrenamiento\n",
        "trainer3.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "-FLUM9TQ9wgP",
        "outputId": "1b900761-3045-4d37-89b8-eb89c97f2e0f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2317' max='2317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2317/2317 00:54]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 1.0,\n",
              " 'eval_accuracy': 0.8457885933200238,\n",
              " 'eval_f1': 0.6625737898465172,\n",
              " 'eval_loss': 0.557986319065094,\n",
              " 'eval_precision': 0.6733861291096712,\n",
              " 'eval_recall': 0.6521031838252382,\n",
              " 'eval_runtime': 54.6536,\n",
              " 'eval_samples_per_second': 339.1,\n",
              " 'eval_steps_per_second': 42.394}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta ocasión al estar balanceado la eficacia del modelo podríamos observarla directamente con la accuracy, que es el total de aciertos, sin importar a la clase que pertenezcan. En esta ocasión se obtiene una accuracy del 85%, que no está nada mal, obteniendo una precision del 67% y recall del 65%, como vemos este modelo sigue sin detectar bien la clase a pesar de obtener una alta accuracy, y esto es debido a que el conjunto de test está muy desbalanceado."
      ],
      "metadata": {
        "id": "zZKD9ruXeutz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer7 = Trainer(\n",
        "    model=model1,                         # modelo a entrenar\n",
        "    args=training_args1,                  # argumentos sobre los que se va a entrenar\n",
        "    train_dataset=train_dataset,         # dataset de entrenamiento\n",
        "    eval_dataset=valid_dataset,          # dataset de evaluación\n",
        "    compute_metrics=matriz_confusion,     # calcula las métricas de intereés\n",
        ")"
      ],
      "metadata": {
        "id": "AJiO_fCHXQ6V"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer7.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "Besll5nCXQ-2",
        "outputId": "93d40dd0-bde3-498b-f56e-71535e0d1dcf"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 9074\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2269\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2269' max='2269' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2269/2269 06:29, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Tn</th>\n",
              "      <th>Fp</th>\n",
              "      <th>Fn</th>\n",
              "      <th>Tp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.602800</td>\n",
              "      <td>0.697690</td>\n",
              "      <td>460</td>\n",
              "      <td>13770</td>\n",
              "      <td>8</td>\n",
              "      <td>4295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.714800</td>\n",
              "      <td>0.649001</td>\n",
              "      <td>14230</td>\n",
              "      <td>0</td>\n",
              "      <td>4303</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-800\n",
            "Configuration saved in ./results/checkpoint-800/config.json\n",
            "Model weights saved in ./results/checkpoint-800/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1600\n",
            "Configuration saved in ./results/checkpoint-1600/config.json\n",
            "Model weights saved in ./results/checkpoint-1600/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-1600 (score: 0.6490011811256409).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2269, training_loss=0.620602684643049, metrics={'train_runtime': 389.6361, 'train_samples_per_second': 23.288, 'train_steps_per_second': 5.823, 'total_flos': 484954786130880.0, 'train_loss': 0.620602684643049, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer7.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "alVXlVzsXXs8",
        "outputId": "3bf2bd25-c13c-42f7-fb32-537808745a74"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2317' max='2317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2317/2317 00:54]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 1.0,\n",
              " 'eval_FN': 4303,\n",
              " 'eval_FP': 0,\n",
              " 'eval_TN': 14230,\n",
              " 'eval_TP': 0,\n",
              " 'eval_loss': 0.6490011811256409,\n",
              " 'eval_runtime': 54.1814,\n",
              " 'eval_samples_per_second': 342.055,\n",
              " 'eval_steps_per_second': 42.764}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que este modelo está asignando a todos que es negativo, ya que el conjunto de test estaba desbalanceado y no hicimos nada por solucionar esto.\n",
        "Este modelo sería un auténtico fracaso pues es lo mismo que no tener modelo, simplemente decimos que todas las noticias no son clickbait, cosa que es errónea."
      ],
      "metadata": {
        "id": "k-MdsV1U3pBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer4 = Trainer(\n",
        "    model=model1,                         # modelo a entrenar\n",
        "    args=training_args2,                  # argumentos sobre los que se va a entrenar\n",
        "    train_dataset=train_dataset,         # dataset de entrenamiento\n",
        "    eval_dataset=valid_dataset,          # dataset de evaluación\n",
        "    compute_metrics=compute_metrics,     # calcula las métricas de intereés\n",
        ")"
      ],
      "metadata": {
        "id": "hu_yIg1U937S"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "trainer4.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "zQI5L2BJ939y",
        "outputId": "f678ed0a-5567-497b-eee8-f5bd2a23dbd9"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 9074\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2270\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2270' max='2270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2270/2270 09:36, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.584500</td>\n",
              "      <td>0.534691</td>\n",
              "      <td>0.637026</td>\n",
              "      <td>0.923774</td>\n",
              "      <td>0.383169</td>\n",
              "      <td>0.541664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.564500</td>\n",
              "      <td>0.619158</td>\n",
              "      <td>0.537582</td>\n",
              "      <td>0.955612</td>\n",
              "      <td>0.329197</td>\n",
              "      <td>0.489699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.564800</td>\n",
              "      <td>0.606394</td>\n",
              "      <td>0.547348</td>\n",
              "      <td>0.951429</td>\n",
              "      <td>0.333551</td>\n",
              "      <td>0.493937</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-600\n",
            "Configuration saved in ./results/checkpoint-600/config.json\n",
            "Model weights saved in ./results/checkpoint-600/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1200\n",
            "Configuration saved in ./results/checkpoint-1200/config.json\n",
            "Model weights saved in ./results/checkpoint-1200/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1800\n",
            "Configuration saved in ./results/checkpoint-1800/config.json\n",
            "Model weights saved in ./results/checkpoint-1800/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-600 (score: 0.5346907377243042).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2270, training_loss=0.5668702919577712, metrics={'train_runtime': 576.8254, 'train_samples_per_second': 31.462, 'train_steps_per_second': 3.935, 'total_flos': 969909572261760.0, 'train_loss': 0.5668702919577712, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos el mejor modelo obtenido después del entrenamiento\n",
        "trainer4.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "6TcTOfuS94AP",
        "outputId": "8f1a5793-432c-437f-b93c-770ae68032c6"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2317' max='2317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2317/2317 00:54]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_accuracy': 0.6370258457885933,\n",
              " 'eval_f1': 0.5416638277577162,\n",
              " 'eval_loss': 0.5346907377243042,\n",
              " 'eval_precision': 0.38316946211683056,\n",
              " 'eval_recall': 0.9237741110852893,\n",
              " 'eval_runtime': 54.3192,\n",
              " 'eval_samples_per_second': 341.187,\n",
              " 'eval_steps_per_second': 42.655}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se obtiene una precision muy baja del 38%, y un recall del 92%, bastante alta, por lo que detecta bien la clase, pero también incluye muestras de la otra clase. La accuracy a disminuido bastante."
      ],
      "metadata": {
        "id": "go01ZwXG4cId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer8 = Trainer(\n",
        "    model=model1,                         # modelo a entrenar\n",
        "    args=training_args2,                  # argumentos sobre los que se va a entrenar\n",
        "    train_dataset=train_dataset,         # dataset de entrenamiento\n",
        "    eval_dataset=valid_dataset,          # dataset de evaluación\n",
        "    compute_metrics=matriz_confusion,     # calcula las métricas de intereés\n",
        ")"
      ],
      "metadata": {
        "id": "7ro2WgIUR5Fj"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "trainer8.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "wxTDeh-lR7lK",
        "outputId": "8372135e-a8d4-4534-848c-c61f4bb707f6"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 9074\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2270\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2270' max='2270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2270/2270 09:35, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Tn</th>\n",
              "      <th>Fp</th>\n",
              "      <th>Fn</th>\n",
              "      <th>Tp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.622200</td>\n",
              "      <td>0.698849</td>\n",
              "      <td>0</td>\n",
              "      <td>14230</td>\n",
              "      <td>0</td>\n",
              "      <td>4303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.701800</td>\n",
              "      <td>0.682912</td>\n",
              "      <td>14230</td>\n",
              "      <td>0</td>\n",
              "      <td>4303</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.698700</td>\n",
              "      <td>0.705634</td>\n",
              "      <td>0</td>\n",
              "      <td>14230</td>\n",
              "      <td>0</td>\n",
              "      <td>4303</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-600\n",
            "Configuration saved in ./results/checkpoint-600/config.json\n",
            "Model weights saved in ./results/checkpoint-600/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1200\n",
            "Configuration saved in ./results/checkpoint-1200/config.json\n",
            "Model weights saved in ./results/checkpoint-1200/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1800\n",
            "Configuration saved in ./results/checkpoint-1800/config.json\n",
            "Model weights saved in ./results/checkpoint-1800/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-1200 (score: 0.6829124689102173).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2270, training_loss=0.6793155485312844, metrics={'train_runtime': 575.2017, 'train_samples_per_second': 31.551, 'train_steps_per_second': 3.946, 'total_flos': 969909572261760.0, 'train_loss': 0.6793155485312844, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer8.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "bzwUiD_HR-RF",
        "outputId": "e7f3e38a-525e-4a28-8d67-5a0a064beacf"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 18533\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2317' max='2317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2317/2317 00:53]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_FN': 4303,\n",
              " 'eval_FP': 0,\n",
              " 'eval_TN': 14230,\n",
              " 'eval_TP': 0,\n",
              " 'eval_loss': 0.6829124689102173,\n",
              " 'eval_runtime': 53.9564,\n",
              " 'eval_samples_per_second': 343.481,\n",
              " 'eval_steps_per_second': 42.942}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que en el caso anterior está asignando a todo que es no-clickbait, este modelo no tendría ningún uso en la vida real, y ambos serían totalmente desechados."
      ],
      "metadata": {
        "id": "JIMcaerM4284"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para poder obtener resultados distintos tendríamos que balancear también los datos test, pero cuantas más transformaciones hagamos más nos estamos alejando de la realidad, por lo que hasta el momento nos quedaríamos hasta aquí.\n",
        "\n",
        "Concluimos que como mejor modelo sería aquel con las clases desbalanceadas que obtuvimos sin transformar el dataset, además de reflejar lo que muestra la realidad, y no usar transformaciones y alterar dicha realidad.\n",
        "\n",
        "Como proyectos futuros quedaría probar diferentes modelos preentrenados, además de seguir tuneando los parámetros del modelo ya entrenado para seguir consiguiendo mejores resultados."
      ],
      "metadata": {
        "id": "B0AfM5Ph5Inu"
      }
    }
  ]
}